import os
import asyncio
import sys
import time
import re
import collections
from dotenv import load_dotenv
from telethon.sync import TelegramClient

# ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# --- è·¯å¾„å®šä¹‰ ---
SESSION_NAME = 'session_name'
CACHE_DIR = 'cache'
LAST_ID_DIR = os.path.join(CACHE_DIR, 'last_ids')
DOWNLOADS_DIR = os.path.join(CACHE_DIR, 'downloads')
LOCK_FILE = os.path.join(CACHE_DIR, 'forwarder.lock')


# =================================================================
#  è¾…åŠ©å‡½æ•° (IDè·å–ã€ç¼“å­˜è¯»å†™ã€é“¾æ¥æå–)
# =================================================================
async def get_channel_id_by_identifier(client, identifier):
    """ï¼ˆå¼‚æ­¥ï¼‰é€šè¿‡æ ‡è¯†ç¬¦è·å–å•ä¸ªé¢‘é“çš„IDã€‚"""
    entity_to_get = identifier
    if identifier.startswith('+'):
        entity_to_get = f"https://t.me/{identifier}"
    try:
        print(f"æ­£åœ¨è§£æ: {entity_to_get}")
        entity = await client.get_entity(entity_to_get)
        print(f"âœ… æ ‡è¯†ç¬¦ '{identifier}' -> ID: {entity.id}")
        return entity.id
    except Exception as e:
        print(f"âŒ è§£ææ ‡è¯†ç¬¦ '{identifier}' æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None


async def get_channel_ids_from_identifiers(client, identifiers):
    """ï¼ˆå¼‚æ­¥ï¼‰æ¥æ”¶ä¸€ä¸ªæ ‡è¯†ç¬¦åˆ—è¡¨ï¼Œè¿”å›æ‰€æœ‰æœ‰æ•ˆé¢‘é“çš„IDåˆ—è¡¨ã€‚"""
    print("\n--- å¼€å§‹æ‰¹é‡è·å–é¢‘é“ID ---")
    tasks = [get_channel_id_by_identifier(client, identifier) for identifier in identifiers]
    results = await asyncio.gather(*tasks)
    valid_ids = [res for res in results if res is not None]
    print(f"--- æ‰¹é‡è·å–å®Œæˆï¼ŒæˆåŠŸæ‰¾åˆ° {len(valid_ids)} ä¸ªæœ‰æ•ˆID ---\n")
    return valid_ids


def get_last_id(channel_id):
    """ä¸ºæŒ‡å®šé¢‘é“è·å–æœ€åè½¬å‘çš„æ¶ˆæ¯ID"""
    file_path = os.path.join(LAST_ID_DIR, f"{channel_id}.txt")
    if os.path.exists(file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            try:
                return int(f.read().strip())
            except (ValueError, IndexError):
                return 0
    return 0


def save_last_id(channel_id, message_id):
    """ä¸ºæŒ‡å®šé¢‘é“ä¿å­˜æœ€åè½¬å‘çš„æ¶ˆæ¯ID"""
    os.makedirs(LAST_ID_DIR, exist_ok=True)
    file_path = os.path.join(LAST_ID_DIR, f"{channel_id}.txt")
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(str(message_id))


def extract_quark_link(text):
    """ä»æ–‡æœ¬ä¸­æå–ç¬¬ä¸€ä¸ªå¤¸å…‹ç½‘ç›˜é“¾æ¥ã€‚"""
    if not text:
        return None
    match = re.search(r"https://pan\.quark\.cn/s/[a-zA-Z0-9]+", text)
    return match.group(0) if match else None


# =================================================================
#  æ ¸å¿ƒè½¬å‘ä¸æ¸…ç†åŠŸèƒ½å‡½æ•°
# =================================================================
async def forward_message_task(client, message, destination_channel, blacklist):
    """å¤„ç†å•æ¡æ¶ˆæ¯çš„è½¬å‘ä»»åŠ¡ï¼ˆåªåŒ…å«å…³é”®è¯è¿‡æ»¤å’Œå®é™…å‘é€ï¼‰ã€‚"""
    media_path = None
    try:
        full_text = (message.text or message.caption or "").lower()

        # å…³é”®è¯è¿‡æ»¤
        if blacklist and full_text:
            if any(keyword in full_text for keyword in blacklist):
                print(f"ğŸ¤« æ¶ˆæ¯ ID {message.id} (å…³é”®è¯è¿‡æ»¤)ï¼Œå·²è·³è¿‡ã€‚")
                return None

        if not message.text and not message.media: return None

        print(f"â¡ï¸ æ­£åœ¨è½¬å‘æ¥è‡ªé¢‘é“ {message.chat_id} çš„æ¶ˆæ¯ ID: {message.id}")
        if message.media:
            os.makedirs(DOWNLOADS_DIR, exist_ok=True)
            media_path = await message.download_media(file=DOWNLOADS_DIR)

        await client.send_message(destination_channel, message.text, file=media_path)

        print(f"âœ… å·²æˆåŠŸè½¬å‘æ¶ˆæ¯ ID {message.id} åˆ° {destination_channel}")
        return message.id
    except Exception as e:
        print(f"âŒ è½¬å‘æ¶ˆæ¯ ID {message.id} æ—¶å‡ºé”™: {e}")
        return None
    finally:
        if media_path and os.path.exists(media_path):
            os.remove(media_path)


async def cleanup_and_get_historical_links(client, config):
    """ã€æ–°åŠŸèƒ½ã€‘æ¸…ç†ç›®æ ‡é¢‘é“ä¸­çš„é‡å¤é“¾æ¥æ¶ˆæ¯ï¼Œå¹¶è¿”å›æ¸…ç†åçš„é“¾æ¥é›†åˆã€‚"""
    if not config['dedup_enabled']:
        return set()

    print("\n--- å¼€å§‹é¢„æ¸…ç†ç›®æ ‡é¢‘é“ ---")
    destination_channel = config['destination_channel']
    limit = config['dedup_cache_size']

    try:
        print(f"æ­£åœ¨åŠ è½½ç›®æ ‡é¢‘é“æœ€è¿‘çš„ {limit} æ¡æ¶ˆæ¯è¿›è¡Œé¢„æ¸…ç†...")

        link_groups = collections.defaultdict(list)

        async for message in client.iter_messages(destination_channel, limit=limit):
            link = extract_quark_link(message.text or message.caption)
            if link:
                # æŒ‰é“¾æ¥åˆ†ç»„ï¼Œå¹¶æŒ‰æ¶ˆæ¯IDæ’åºï¼ˆå¤§â†’å°ï¼Œå³æ–°â†’æ—§ï¼‰
                link_groups[link].append(message)
                link_groups[link].sort(key=lambda m: m.id, reverse=True)

        ids_to_delete = []
        final_links = set()
        for link, messages in link_groups.items():
            final_links.add(link)  # ä¿ç•™è¿™ä¸ªé“¾æ¥
            if len(messages) > 1:
                # ä¿ç•™æœ€æ–°çš„æ¶ˆæ¯ (messages[0])ï¼Œåˆ é™¤å…¶ä½™çš„
                messages_to_delete = messages[1:]
                delete_ids = [msg.id for msg in messages_to_delete]
                ids_to_delete.extend(delete_ids)
                print(f"  - å‘ç°é‡å¤é“¾æ¥: {link}")
                print(f"    - ä¿ç•™æœ€æ–°æ¶ˆæ¯ ID: {messages[0].id}")
                print(f"    - å‡†å¤‡åˆ é™¤æ—§æ¶ˆæ¯: {delete_ids}")

        if ids_to_delete:
            await client.delete_messages(destination_channel, ids_to_delete)
            print(f"\né¢„æ¸…ç†å®Œæ¯•ï¼Œå…±åˆ é™¤äº† {len(ids_to_delete)} æ¡é‡å¤æ¶ˆæ¯ã€‚")
        else:
            print("é¢„æ¸…ç†å®Œæˆï¼Œæ²¡æœ‰å‘ç°éœ€è¦åˆ é™¤çš„é‡å¤æ¶ˆæ¯ã€‚")

        return final_links

    except Exception as e:
        print(f"âŒ æ¸…ç†ç›®æ ‡é¢‘é“æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return set()  # å‡ºé”™æ—¶è¿”å›ç©ºé›†åˆï¼Œé¿å…å½±å“åç»­æµç¨‹
    finally:
        print("--- ç›®æ ‡é¢‘é“é¢„æ¸…ç†ç»“æŸ ---\n")


async def main():
    """è¿è¡Œæ¶ˆæ¯è½¬å‘è„šæœ¬çš„ä¸»å‡½æ•°"""
    # --- ä» .env æ–‡ä»¶åŠ è½½æ‰€æœ‰é…ç½® ---
    config = {
        'api_id': os.environ.get('API_ID'),
        'api_hash': os.environ.get('API_HASH'),
        'destination_channel': os.environ.get('DESTINATION_CHANNEL'),
        'identifiers_string': os.environ.get('CHANNEL_IDENTIFIERS'),
        'ids_string': os.environ.get('CHANNEL_IDS'),
        'blacklist_string': os.environ.get('KEYWORD_BLACKLIST'),
        'dedup_enabled': os.environ.get('DEDUPLICATION_ENABLED', 'false').lower() == 'true',
        'dedup_cache_size': int(os.environ.get('DEDUPLICATION_CACHE_SIZE', 200))
    }

    config['blacklist'] = [k.strip().lower() for k in config['blacklist_string'].split(',') if k.strip()] if config[
        'blacklist_string'] else []
    if config['blacklist']:
        print(f"å·²åŠ è½½å…³é”®è¯é»‘åå•: {config['blacklist']}")

    if not all([config['api_id'], config['api_hash'], config['destination_channel']]):
        print("é”™è¯¯ï¼šè¯·ç¡®ä¿ .env æ–‡ä»¶ä¸­å·²é…ç½® API_ID, API_HASH, å’Œ DESTINATION_CHANNELã€‚")
        return

    async with TelegramClient(SESSION_NAME, config['api_id'], config['api_hash']) as client:
        print("å·²é€šè¿‡ä¼šè¯æ–‡ä»¶æˆåŠŸç™»å½•ã€‚")
        print("æ­£åœ¨é¢„çƒ­ä¼šè¯ç¼“å­˜...")
        await client.get_dialogs()
        print("ç¼“å­˜é¢„çƒ­å®Œæ¯•ã€‚")

        # --- ã€æ–°é€»è¾‘ã€‘ç¬¬ä¸€æ­¥ï¼šé¢„æ¸…ç†ç›®æ ‡é¢‘é“å¹¶è·å–å†å²é“¾æ¥ ---
        historical_links = await cleanup_and_get_historical_links(client, config)

        # --- è·å–æºé¢‘é“ID ---
        source_channel_ids = []
        if config['ids_string']:
            print("æ£€æµ‹åˆ° CHANNEL_IDS é…ç½®ï¼Œå°†ç›´æ¥ä½¿ç”¨æä¾›çš„IDã€‚")
            try:
                source_channel_ids = [int(id_str.strip()) for id_str in config['ids_string'].split(',') if
                                      id_str.strip()]
            except ValueError:
                print("é”™è¯¯ï¼šCHANNEL_IDS æ ¼å¼ä¸æ­£ç¡®ã€‚")
                return
        elif config['identifiers_string']:
            print("æœªé…ç½® CHANNEL_IDSï¼Œå°†ä½¿ç”¨ CHANNEL_IDENTIFIERSã€‚")
            identifiers = [i.strip() for i in config['identifiers_string'].split(',') if i.strip()]
            source_channel_ids = await get_channel_ids_from_identifiers(client, identifiers)
        else:
            print("é”™è¯¯ï¼šå¿…é¡»é…ç½® CHANNEL_IDS æˆ– CHANNEL_IDENTIFIERSã€‚")
            return

        if not source_channel_ids:
            print("æœªèƒ½è·å–ä»»ä½•æœ‰æ•ˆçš„æºé¢‘é“IDï¼Œç¨‹åºé€€å‡ºã€‚")
            return

        print(f"ç¨‹åºå°†ä»ä»¥ä¸‹æºé¢‘é“IDè¿›è¡Œè½¬å‘: {source_channel_ids}")

        # --- ã€æ–°é€»è¾‘ã€‘ç¬¬äºŒæ­¥ï¼šä»æ‰€æœ‰æºé¢‘é“æ”¶é›†æ–°æ¶ˆæ¯ ---
        all_new_messages = []
        latest_ids_map = {}
        for channel_id in source_channel_ids:
            last_id = get_last_id(channel_id)
            print(f"æ­£åœ¨ä»é¢‘é“ {channel_id} æ”¶é›†è‡ª ID {last_id + 1} ä»¥æ¥çš„æ–°æ¶ˆæ¯...")
            channel_messages = [msg async for msg in client.iter_messages(channel_id, min_id=last_id)]
            if channel_messages:
                all_new_messages.extend(channel_messages)
                latest_ids_map[channel_id] = max(m.id for m in channel_messages)

        if not all_new_messages:
            print("æ‰€æœ‰æºé¢‘é“éƒ½æ²¡æœ‰æ‰¾åˆ°æ–°æ¶ˆæ¯ã€‚")
            # å³ä½¿æ²¡æœ‰æ–°æ¶ˆæ¯ï¼Œä¹Ÿéœ€è¦æ›´æ–° last_idï¼Œä»¥é˜²æœ‰è¢«åˆ é™¤çš„æ¶ˆæ¯
            for channel_id in source_channel_ids:
                if channel_id not in latest_ids_map:
                    # å°è¯•è·å–é¢‘é“çš„æœ€æ–°æ¶ˆæ¯ID
                    try:
                        async for last_msg in client.iter_messages(channel_id, limit=1):
                            save_last_id(channel_id, last_msg.id)
                            print(f"é¢‘é“ {channel_id} æ— æ–°æ¶ˆæ¯ï¼Œä½†å°† last_id æ›´æ–°è‡³ {last_msg.id}")
                    except Exception:
                        pass  # å¦‚æœé¢‘é“æ— æ³•è®¿é—®ï¼Œåˆ™è·³è¿‡
            return

        all_new_messages.sort(key=lambda m: m.date)
        print(f"\nä»æ‰€æœ‰é¢‘é“å…±æ”¶é›†åˆ° {len(all_new_messages)} æ¡æ–°æ¶ˆæ¯ï¼Œå¼€å§‹ç»Ÿä¸€è¿‡æ»¤...")

        final_messages = all_new_messages
        dedup_enabled = config['dedup_enabled']

        # --- ã€æ–°é€»è¾‘ã€‘ç¬¬ä¸‰æ­¥ï¼šå¯¹åˆå¹¶åçš„æ¶ˆæ¯åˆ—è¡¨è¿›è¡Œè¿‡æ»¤ ---
        if dedup_enabled:
            # --- é˜¶æ®µä¸€ï¼šæœ¬æ¬¡è¿è¡Œå†…éƒ¨å»é‡ ---
            print("  - é˜¶æ®µä¸€ï¼šå¤„ç†æœ¬æ¬¡è¿è¡Œå†…çš„é‡å¤é“¾æ¥...")
            link_map = {}
            messages_without_link_stage1 = []
            for msg in all_new_messages:
                link = extract_quark_link(msg.text or msg.caption)
                if link:
                    if link not in link_map or msg.id > link_map[link].id:
                        link_map[link] = msg
                else:
                    messages_without_link_stage1.append(msg)

            messages_after_stage1 = list(link_map.values()) + messages_without_link_stage1
            messages_after_stage1.sort(key=lambda m: m.date)
            print(f"  - é˜¶æ®µä¸€åå‰©ä½™ {len(messages_after_stage1)} æ¡æ¶ˆæ¯ã€‚")

            # --- é˜¶æ®µäºŒï¼šä¸ç›®æ ‡é¢‘é“å†å²è®°å½•æ¯”å¯¹å»é‡ ---
            print(f"  - é˜¶æ®µäºŒï¼šä¸ç›®æ ‡é¢‘é“å†å²é“¾æ¥æ¯”å¯¹...")
            messages_after_stage2 = []
            for msg in messages_after_stage1:
                link = extract_quark_link(msg.text or msg.caption)
                # å¦‚æœæ¶ˆæ¯æ²¡æœ‰é“¾æ¥ï¼Œç›´æ¥é€šè¿‡
                if not link:
                    messages_after_stage2.append(msg)
                    continue
                # å¦‚æœæœ‰é“¾æ¥ï¼Œä¸”é“¾æ¥ä¸å­˜åœ¨äºå†å²è®°å½•ä¸­ï¼Œåˆ™é€šè¿‡
                if link not in historical_links:
                    messages_after_stage2.append(msg)
                else:
                    print(f"ğŸ¤« æ¶ˆæ¯ ID {msg.id} (é“¾æ¥å·²å­˜åœ¨äºç›®æ ‡é¢‘é“)ï¼Œå·²è·³è¿‡ã€‚")

            final_messages = messages_after_stage2
            print(f"  - é˜¶æ®µäºŒåå‰©ä½™ {len(final_messages)} æ¡æ¶ˆæ¯ã€‚")

        # --- ã€æ–°é€»è¾‘ã€‘ç¬¬å››æ­¥ï¼šé¡ºåºå¤„ç†æœ€ç»ˆç­›é€‰å‡ºçš„æ¶ˆæ¯ ---
        print(f"è¿‡æ»¤å®Œæˆï¼Œæœ€ç»ˆæœ‰ {len(final_messages)} æ¡æ¶ˆæ¯å‡†å¤‡è½¬å‘ã€‚")
        for message in final_messages:
            await forward_message_task(client, message, config['destination_channel'], config['blacklist'])

        # --- ã€æ–°é€»è¾‘ã€‘ç¬¬äº”æ­¥ï¼šæ›´æ–°æ‰€æœ‰é¢‘é“çš„ last_id ---
        if latest_ids_map:
            print("\n--- æ›´æ–°æ‰€æœ‰é¢‘é“çš„ last_id ---")
            for channel_id, max_id in latest_ids_map.items():
                save_last_id(channel_id, max_id)
                print(f"  - é¢‘é“ {channel_id} çš„æœ€æ–°æ¶ˆæ¯ ID å·²æ›´æ–°ä¸º: {max_id}")

    print(f"\n[{time.strftime('%Y-%m-%d %H:%M:%S')}] æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆã€‚")


if __name__ == '__main__':
    os.makedirs(CACHE_DIR, exist_ok=True)
    if os.path.exists(LOCK_FILE):
        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] æ£€æµ‹åˆ°é”æ–‡ä»¶ï¼Œå¦ä¸€ä¸ªå®ä¾‹å¯èƒ½æ­£åœ¨è¿è¡Œï¼Œæœ¬æ¬¡ä»»åŠ¡è·³è¿‡ã€‚")
        sys.exit()

    try:
        with open(LOCK_FILE, 'w') as f:
            f.write(str(os.getpid()))

        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] ç¨‹åºå¼€å§‹è¿è¡Œ...")
        asyncio.run(main())

    except Exception as e:
        print(f"ç¨‹åºè¿è¡Œæ—¶å‘ç”Ÿæœªæ•è·çš„é”™è¯¯: {e}")
    finally:
        if os.path.exists(LOCK_FILE):
            os.remove(LOCK_FILE)
            print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] é”æ–‡ä»¶å·²ç§»é™¤ã€‚")
